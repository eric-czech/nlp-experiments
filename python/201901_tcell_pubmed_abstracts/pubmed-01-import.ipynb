{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "console = logging.StreamHandler()\n",
    "console.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s:%(name)s: %(message)s'))\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel('INFO')\n",
    "logger.addHandler(console)\n",
    "output_dir = '/Users/eczech/tmp/nlp/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def search(query, retstart=0, retmax=1000):\n",
    "    Entrez.email = 'eric@hammerlab.org'\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='relevance', \n",
    "                            retmax=str(retmax),\n",
    "                            retstart=str(retstart),\n",
    "                            retmode='xml', \n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "def parse(dets):\n",
    "    res = {}\n",
    "    dets = dets['MedlineCitation']\n",
    "    res['id'] = str(dets['PMID'])\n",
    "    res['title'] = dets['Article']['ArticleTitle']\n",
    "    try:\n",
    "        res['abstract'] = dets['Article']['Abstract']['AbstractText'][0]\n",
    "    except:\n",
    "        res['abstract'] = None\n",
    "    try:\n",
    "        date = dets['Article']['ArticleDate'][0]\n",
    "        res['date'] = '{}-{}-{}'.format(date['Year'], date['Month'], date['Day'])\n",
    "    except:\n",
    "        res['date'] = None\n",
    "    try:\n",
    "        def get_mesh_terms(v):\n",
    "            return '/'.join([v['DescriptorName']] + v['QualifierName'])\n",
    "        res['terms'] = '|'.join([get_mesh_terms(v) for v in dets['MeshHeadingList']])\n",
    "    except:\n",
    "        res['terms'] = None\n",
    "        \n",
    "    return res\n",
    "\n",
    "def to_df(dets):\n",
    "    return pd.DataFrame([parse(d) for d in dets['PubmedArticle']])\n",
    "\n",
    "def collect(query, output_file, start_index=0, batch_size=100, batch_limit=None, max_failures=5):\n",
    "    i = start_index\n",
    "    ct = 0\n",
    "    failures = 0\n",
    "    while True:\n",
    "        try:\n",
    "            ids = search(query, retstart=i, retmax=batch_size)['IdList']\n",
    "            if len(ids) == 0:\n",
    "                break\n",
    "            logger.info('Processing batch at start index {} (num ids = {})'.format(i, len(ids)))\n",
    "            dets = fetch_details(ids)\n",
    "            df = to_df(dets)\n",
    "            df.to_csv(output_file, index=False, header=not osp.exists(output_file), mode='a')\n",
    "            ct += 1\n",
    "            i += batch_size\n",
    "            if batch_limit and ct >= batch_limit:\n",
    "                break\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            failures += 1\n",
    "            if failures > max_failures:\n",
    "                raise ValueError('Max failure threshold ({}) exceeded'.format(max_failures))\n",
    "            logger.warning('Error occurred at index {}. Will retry up to {} times'.format(i, max_failures))\n",
    "    logger.info('Collection complete (num failures = {})'.format(failures))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-29 17:02:15,743:INFO:root: Processing batch at start index 0 (num ids = 1000)\n",
      "2019-01-29 17:02:34,145:INFO:root: Processing batch at start index 1000 (num ids = 1000)\n",
      "2019-01-29 17:02:50,968:INFO:root: Processing batch at start index 2000 (num ids = 1000)\n",
      "2019-01-29 17:03:08,668:INFO:root: Processing batch at start index 3000 (num ids = 1000)\n",
      "2019-01-29 17:03:26,944:INFO:root: Processing batch at start index 4000 (num ids = 1000)\n",
      "2019-01-29 17:03:46,505:INFO:root: Processing batch at start index 5000 (num ids = 1000)\n",
      "2019-01-29 17:04:00,996:INFO:root: Processing batch at start index 6000 (num ids = 1000)\n",
      "2019-01-29 17:04:17,830:INFO:root: Processing batch at start index 7000 (num ids = 1000)\n",
      "2019-01-29 17:04:32,039:INFO:root: Processing batch at start index 8000 (num ids = 1000)\n",
      "2019-01-29 17:04:48,625:INFO:root: Processing batch at start index 9000 (num ids = 1000)\n",
      "2019-01-29 17:05:04,142:INFO:root: Processing batch at start index 10000 (num ids = 1000)\n",
      "2019-01-29 17:05:21,247:INFO:root: Processing batch at start index 11000 (num ids = 1000)\n",
      "2019-01-29 17:05:38,695:INFO:root: Processing batch at start index 12000 (num ids = 1000)\n",
      "2019-01-29 17:05:53,776:INFO:root: Processing batch at start index 13000 (num ids = 1000)\n",
      "2019-01-29 17:06:10,305:INFO:root: Processing batch at start index 14000 (num ids = 1000)\n",
      "2019-01-29 17:06:30,084:INFO:root: Processing batch at start index 15000 (num ids = 1000)\n",
      "2019-01-29 17:06:43,315:INFO:root: Processing batch at start index 16000 (num ids = 1000)\n",
      "2019-01-29 17:07:00,896:INFO:root: Processing batch at start index 17000 (num ids = 1000)\n",
      "2019-01-29 17:07:14,222:INFO:root: Processing batch at start index 18000 (num ids = 1000)\n",
      "2019-01-29 17:07:31,429:INFO:root: Processing batch at start index 19000 (num ids = 1000)\n",
      "2019-01-29 17:07:43,904:INFO:root: Processing batch at start index 20000 (num ids = 1000)\n",
      "2019-01-29 17:07:56,831:INFO:root: Processing batch at start index 21000 (num ids = 1000)\n",
      "2019-01-29 17:08:12,904:INFO:root: Processing batch at start index 22000 (num ids = 1000)\n",
      "2019-01-29 17:08:25,709:INFO:root: Processing batch at start index 23000 (num ids = 1000)\n",
      "2019-01-29 17:08:37,770:INFO:root: Processing batch at start index 24000 (num ids = 1000)\n",
      "2019-01-29 17:08:53,354:INFO:root: Processing batch at start index 25000 (num ids = 1000)\n",
      "2019-01-29 17:09:06,845:INFO:root: Processing batch at start index 26000 (num ids = 1000)\n",
      "2019-01-29 17:09:18,392:INFO:root: Processing batch at start index 27000 (num ids = 1000)\n",
      "2019-01-29 17:09:30,257:INFO:root: Processing batch at start index 28000 (num ids = 1000)\n",
      "2019-01-29 17:09:46,079:INFO:root: Processing batch at start index 29000 (num ids = 1000)\n",
      "2019-01-29 17:09:57,080:INFO:root: Processing batch at start index 30000 (num ids = 1000)\n",
      "2019-01-29 17:10:07,722:INFO:root: Processing batch at start index 31000 (num ids = 1000)\n",
      "2019-01-29 17:10:19,355:INFO:root: Processing batch at start index 32000 (num ids = 1000)\n",
      "2019-01-29 17:10:29,658:INFO:root: Processing batch at start index 33000 (num ids = 1000)\n",
      "2019-01-29 17:10:40,176:INFO:root: Processing batch at start index 34000 (num ids = 1000)\n",
      "2019-01-29 17:10:50,802:INFO:root: Processing batch at start index 35000 (num ids = 1000)\n",
      "2019-01-29 17:11:07,128:INFO:root: Processing batch at start index 36000 (num ids = 1000)\n",
      "2019-01-29 17:11:18,021:INFO:root: Processing batch at start index 37000 (num ids = 1000)\n",
      "2019-01-29 17:11:31,099:INFO:root: Processing batch at start index 38000 (num ids = 1000)\n",
      "2019-01-29 17:11:40,258:INFO:root: Processing batch at start index 39000 (num ids = 1000)\n",
      "2019-01-29 17:11:50,508:INFO:root: Processing batch at start index 40000 (num ids = 1000)\n",
      "2019-01-29 17:11:59,928:INFO:root: Processing batch at start index 41000 (num ids = 1000)\n",
      "2019-01-29 17:12:09,302:INFO:root: Processing batch at start index 42000 (num ids = 1000)\n",
      "2019-01-29 17:12:19,361:INFO:root: Processing batch at start index 43000 (num ids = 1000)\n",
      "2019-01-29 17:12:28,513:INFO:root: Processing batch at start index 44000 (num ids = 1000)\n",
      "2019-01-29 17:12:39,071:INFO:root: Processing batch at start index 45000 (num ids = 1000)\n",
      "2019-01-29 17:12:51,951:INFO:root: Processing batch at start index 46000 (num ids = 1000)\n",
      "2019-01-29 17:12:59,856:INFO:root: Processing batch at start index 47000 (num ids = 1000)\n",
      "2019-01-29 17:13:10,375:INFO:root: Processing batch at start index 48000 (num ids = 1000)\n",
      "2019-01-29 17:13:20,055:INFO:root: Processing batch at start index 49000 (num ids = 1000)\n",
      "2019-01-29 17:13:30,553:INFO:root: Processing batch at start index 50000 (num ids = 1000)\n",
      "2019-01-29 17:13:40,388:INFO:root: Processing batch at start index 51000 (num ids = 1000)\n",
      "2019-01-29 17:13:51,572:INFO:root: Processing batch at start index 52000 (num ids = 174)\n",
      "2019-01-29 17:13:53,556:INFO:root: Collection complete (num failures = 0)\n"
     ]
    }
   ],
   "source": [
    "!rm $output_dir/pubmed_abstracts.csv\n",
    "#query = 'T cells OR T lymphocytes'\n",
    "query = '\"humans\"[MeSH Terms] AND \"t lymphocyte subsets/immunology\"[MeSH Terms]'\n",
    "collect(\n",
    "    query, osp.join(output_dir, 'pubmed_abstracts.csv'), \n",
    "    start_index=0, batch_size=1000, batch_limit=None, max_failures=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>terms</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sodium chloride (NaCl) has been proposed as a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30554495</td>\n",
       "      <td>Animals|Arthritis, Experimental/immunology/pat...</td>\n",
       "      <td>Sodium Chloride Aggravates Arthritis via Th17 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The severity of cryptococcosis in lupus from v...</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>30456753</td>\n",
       "      <td>Animals|Cryptococcosis/etiology/genetics/immun...</td>\n",
       "      <td>Increased susceptibility against Cryptococcus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For efficacy of peptide vaccination immunother...</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>30375705</td>\n",
       "      <td>Amino Acid Sequence|Antigen Presentation/immun...</td>\n",
       "      <td>Development of a T-cell receptor multimer with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronchopulmonary dysplasia (BPD) is one of the...</td>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>30324231</td>\n",
       "      <td>Biomarkers/blood|Bronchopulmonary Dysplasia/bl...</td>\n",
       "      <td>Increased serum Th2 chemokine levels are assoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast cancer remains one of the leading cause...</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>30283982</td>\n",
       "      <td>Adult|Aged|Breast Neoplasms/immunology/patholo...</td>\n",
       "      <td>An autologous dendritic cell vaccine polarizes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract        date        id  \\\n",
       "0  Sodium chloride (NaCl) has been proposed as a ...         NaN  30554495   \n",
       "1  The severity of cryptococcosis in lupus from v...  2018-11-19  30456753   \n",
       "2  For efficacy of peptide vaccination immunother...  2018-12-01  30375705   \n",
       "3  Bronchopulmonary dysplasia (BPD) is one of the...  2018-10-15  30324231   \n",
       "4  Breast cancer remains one of the leading cause...  2018-10-03  30283982   \n",
       "\n",
       "                                               terms  \\\n",
       "0  Animals|Arthritis, Experimental/immunology/pat...   \n",
       "1  Animals|Cryptococcosis/etiology/genetics/immun...   \n",
       "2  Amino Acid Sequence|Antigen Presentation/immun...   \n",
       "3  Biomarkers/blood|Bronchopulmonary Dysplasia/bl...   \n",
       "4  Adult|Aged|Breast Neoplasms/immunology/patholo...   \n",
       "\n",
       "                                               title  \n",
       "0  Sodium Chloride Aggravates Arthritis via Th17 ...  \n",
       "1  Increased susceptibility against Cryptococcus ...  \n",
       "2  Development of a T-cell receptor multimer with...  \n",
       "3  Increased serum Th2 chemokine levels are assoc...  \n",
       "4  An autologous dendritic cell vaccine polarizes...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(osp.join(output_dir, 'pubmed_abstracts.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].value_counts().max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
